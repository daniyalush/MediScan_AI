{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a859ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 5712, Testing samples: 1311\n",
      "Epoch [1/15], Loss: 0.7429, Accuracy: 70.57%\n",
      "Epoch [2/15], Loss: 0.4449, Accuracy: 82.58%\n",
      "Epoch [3/15], Loss: 0.3463, Accuracy: 87.20%\n",
      "Epoch [4/15], Loss: 0.2885, Accuracy: 89.32%\n",
      "Epoch [5/15], Loss: 0.2247, Accuracy: 91.00%\n",
      "Epoch [6/15], Loss: 0.1763, Accuracy: 93.73%\n",
      "Epoch [7/15], Loss: 0.1552, Accuracy: 94.10%\n",
      "Epoch [8/15], Loss: 0.1289, Accuracy: 95.31%\n",
      "Epoch [9/15], Loss: 0.1056, Accuracy: 96.18%\n",
      "Epoch [10/15], Loss: 0.0868, Accuracy: 96.95%\n",
      "Epoch [11/15], Loss: 0.0753, Accuracy: 97.18%\n",
      "Epoch [12/15], Loss: 0.0670, Accuracy: 97.57%\n",
      "Epoch [13/15], Loss: 0.0589, Accuracy: 97.79%\n",
      "Epoch [14/15], Loss: 0.0512, Accuracy: 98.20%\n",
      "Epoch [15/15], Loss: 0.0521, Accuracy: 98.27%\n",
      "Test Accuracy: 97.56%\n",
      "Model saved as brain_tumor_model.pth\n"
     ]
    }
   ],
   "source": [
    "# train_model_pytorch.ipynb\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------\n",
    "# CONFIG\n",
    "# ----------------------\n",
    "DATASET_PATH = \"BrainDataset\"\n",
    "IMG_SIZE = 128\n",
    "CATEGORIES = [\"notumor\", \"glioma\", \"meningioma\", \"pituitary\"]\n",
    "NUM_CLASSES = len(CATEGORIES)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ----------------------\n",
    "# Custom Dataset\n",
    "# ----------------------\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, folder_path, categories, transform=None):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        for idx, category in enumerate(categories):\n",
    "            category_path = os.path.join(folder_path, category)\n",
    "            for img_name in os.listdir(category_path):\n",
    "                img_path = os.path.join(category_path, img_name)\n",
    "                self.images.append(img_path)\n",
    "                self.labels.append(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# ----------------------\n",
    "# Transforms\n",
    "# ----------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),               # convert to [0,1] and add channel\n",
    "])\n",
    "\n",
    "# ----------------------\n",
    "# Load datasets\n",
    "# ----------------------\n",
    "train_dataset = BrainTumorDataset(os.path.join(DATASET_PATH, \"Training\"), CATEGORIES, transform=transform)\n",
    "test_dataset  = BrainTumorDataset(os.path.join(DATASET_PATH, \"Testing\"), CATEGORIES, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}, Testing samples: {len(test_dataset)}\")\n",
    "\n",
    "# ----------------------\n",
    "# Define CNN model\n",
    "# ----------------------\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(128*14*14, 128)  # depends on IMG_SIZE=128\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = CNNModel().to(DEVICE)\n",
    "\n",
    "# ----------------------\n",
    "# Loss and optimizer\n",
    "# ----------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ----------------------\n",
    "# Training loop\n",
    "# ----------------------\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total * 100\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "# ----------------------\n",
    "# Evaluate on test set\n",
    "# ----------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_acc = correct / total * 100\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "# ----------------------\n",
    "# Save the trained model\n",
    "# ----------------------\n",
    "torch.save(model.state_dict(), \"brain_tumor_model_weights.pth\")\n",
    "print(\"Model saved as brain_tumor_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e5e6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: 1.1268, Train Acc: 47.31% | Val Loss: 1.0432, Val Acc: 37.50%\n",
      "Epoch 2/20 | Train Loss: 0.8576, Train Acc: 60.36% | Val Loss: 1.3219, Val Acc: 45.83%\n",
      "Epoch 3/20 | Train Loss: 0.8215, Train Acc: 63.95% | Val Loss: 1.0076, Val Acc: 63.89%\n",
      "Epoch 4/20 | Train Loss: 0.6624, Train Acc: 72.92% | Val Loss: 0.8894, Val Acc: 69.44%\n",
      "Epoch 5/20 | Train Loss: 0.5455, Train Acc: 77.98% | Val Loss: 0.8423, Val Acc: 61.11%\n",
      "Epoch 6/20 | Train Loss: 0.5960, Train Acc: 75.86% | Val Loss: 0.6906, Val Acc: 66.67%\n",
      "Epoch 7/20 | Train Loss: 0.4298, Train Acc: 82.54% | Val Loss: 0.8276, Val Acc: 65.28%\n",
      "Epoch 8/20 | Train Loss: 0.3527, Train Acc: 85.97% | Val Loss: 0.7633, Val Acc: 73.61%\n",
      "Epoch 9/20 | Train Loss: 0.2927, Train Acc: 89.07% | Val Loss: 0.6122, Val Acc: 73.61%\n",
      "Epoch 10/20 | Train Loss: 0.1872, Train Acc: 93.15% | Val Loss: 0.7211, Val Acc: 75.00%\n",
      "Epoch 11/20 | Train Loss: 0.2210, Train Acc: 91.19% | Val Loss: 0.6292, Val Acc: 77.78%\n",
      "Epoch 12/20 | Train Loss: 0.1741, Train Acc: 93.15% | Val Loss: 0.7398, Val Acc: 79.17%\n",
      "Epoch 13/20 | Train Loss: 0.1530, Train Acc: 93.96% | Val Loss: 0.6001, Val Acc: 83.33%\n",
      "Epoch 14/20 | Train Loss: 0.1548, Train Acc: 93.80% | Val Loss: 0.7557, Val Acc: 83.33%\n",
      "Epoch 15/20 | Train Loss: 0.0857, Train Acc: 97.55% | Val Loss: 0.7479, Val Acc: 80.56%\n",
      "Epoch 16/20 | Train Loss: 0.1606, Train Acc: 93.96% | Val Loss: 0.8880, Val Acc: 83.33%\n",
      "Epoch 17/20 | Train Loss: 0.1109, Train Acc: 96.08% | Val Loss: 0.7582, Val Acc: 79.17%\n",
      "Epoch 18/20 | Train Loss: 0.1349, Train Acc: 94.45% | Val Loss: 0.7877, Val Acc: 83.33%\n",
      "Epoch 19/20 | Train Loss: 0.1110, Train Acc: 95.92% | Val Loss: 0.8437, Val Acc: 84.72%\n",
      "Epoch 20/20 | Train Loss: 0.1232, Train Acc: 96.08% | Val Loss: 0.8376, Val Acc: 84.72%\n",
      "Test Accuracy: 51.43%\n",
      "Saved model: lung_cnn_model.pth\n"
     ]
    }
   ],
   "source": [
    "# train_lung_cnn.py\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# ----------------------\n",
    "# CONFIG\n",
    "# ----------------------\n",
    "DATASET_PATH = \"LungDataset\"  # main dataset folder containing train/test/valid\n",
    "IMG_SIZE = 128\n",
    "CATEGORIES = [\"adenocarcinoma\", \"large cell carcinoma\", \"squamous cell carcinoma\", \"normal\"]\n",
    "NUM_CLASSES = len(CATEGORIES)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ----------------------\n",
    "# DATASET CLASS\n",
    "# ----------------------\n",
    "class LungDataset(Dataset):\n",
    "    def __init__(self, folder_path, categories, transform=None):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        for idx, category in enumerate(categories):\n",
    "            category_path = os.path.join(folder_path, category)\n",
    "            for img_name in os.listdir(category_path):\n",
    "                img_path = os.path.join(category_path, img_name)\n",
    "                self.images.append(img_path)\n",
    "                self.labels.append(idx)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.images[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "\n",
    "# ----------------------\n",
    "# TRANSFORMS\n",
    "# ----------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# ----------------------\n",
    "# LOAD DATA\n",
    "# ----------------------\n",
    "train_dataset = LungDataset(os.path.join(DATASET_PATH, \"train\"), CATEGORIES, transform=transform)\n",
    "test_dataset  = LungDataset(os.path.join(DATASET_PATH, \"test\"), CATEGORIES, transform=transform)\n",
    "valid_dataset = LungDataset(os.path.join(DATASET_PATH, \"valid\"), CATEGORIES, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# ----------------------\n",
    "# CNN MODEL\n",
    "# ----------------------\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
    "        self.fc1 = nn.Linear(128*14*14, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = CNNModel().to(DEVICE)\n",
    "\n",
    "# ----------------------\n",
    "# LOSS & OPTIMIZER\n",
    "# ----------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ----------------------\n",
    "# TRAINING LOOP\n",
    "# ----------------------\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_acc = correct/total*100\n",
    "    train_loss = running_loss/total\n",
    "    \n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    val_acc = val_correct / val_total * 100\n",
    "    val_loss /= val_total\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "# ----------------------\n",
    "# TEST EVALUATION\n",
    "# ----------------------\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "print(f\"Test Accuracy: {test_correct/test_total*100:.2f}%\")\n",
    "\n",
    "# ----------------------\n",
    "# SAVE MODEL\n",
    "# ----------------------\n",
    "torch.save(model.state_dict(), \"lung_cnn_model.pth\")\n",
    "print(\"Saved model: lung_cnn_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0c8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
